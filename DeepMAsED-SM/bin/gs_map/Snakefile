rule ref_genome_rename:
    """
    Renaming genome fasta file names & sequence headers
    """
    input:
        fna = lambda wildcards: config['genomes_tbl'].loc[config['genomes_tbl'].Taxon == wildcards.genome,'Fasta'].unique().tolist()
    output:
        fna = config['tmp_dir'] + 'gs_map/genomes/{genome}.fna'
    params:
        exe = config['pipeline']['script_folder'] + 'rename_genome.py'
    log:
        log_dir + 'ref_genome_rename/{genome}.log'
    benchmark:
        benchmark_dir + 'ref_genome_rename/{genome}.txt'
    shell:
        """        
        export PATH=$CONDA_PREFIX/bin:$PATH
        {params.exe} {input.fna} > {output.fna} 2> {log}
        """
        
if not skipped(config['nonsim_params']['subsample_reads']):
    rule subsample_read1:
        """
        Subsampling reads
        """
        input:
            reads = lambda wildcards: config['genomes_tbl'].loc[config['genomes_tbl'].Sample == wildcards.sample, 'Read1'].unique().tolist()
        output:
            reads = temp(config['tmp_dir'] + 'gs_map/reads/subsample/{sample}/R1.fq')
        params:
            n = config['nonsim_params']['subsample_reads']
        threads:
            4
        resources:
            time = lambda wildcards, attempt: attempt ** 3 * 59,
            n = lambda wildcards, threads: threads,
	    mem_gb_pt = lambda wildcards, attempt: attempt ** 3 * 4 + 8
        conda:
            '../envs/bowtie2.yaml'
        log:
            log_dir + 'subsample_read1/{sample}.log'
        benchmark:
            benchmark_dir + 'subsample_read1/{sample}.txt'
        shell:
            """
            export PATH=$CONDA_PREFIX/bin:$PATH
            seqkit sample --two-pass -j {threads} -n {params.n} \
              {input.reads} > {output.reads} 2> {log}
            """
    rule subsample_read2:
        """
        Subsampling reads
        """
        input:
            reads = lambda wildcards: config['genomes_tbl'].loc[config['genomes_tbl'].Sample == wildcards.sample, 'Read2'].unique().tolist()
        output:
            reads = temp(config['tmp_dir'] + 'gs_map/reads/subsample/{sample}/R2.fq')
        params:
            n = config['nonsim_params']['subsample_reads']
        threads:
            4
        resources:
            time = lambda wildcards, attempt: attempt ** 3 * 59,
            n = lambda wildcards, threads: threads,
	    mem_gb_pt = lambda wildcards, attempt: attempt ** 3 * 4 + 8
        conda:
            '../envs/bowtie2.yaml'
        log:
            log_dir + 'subsample_read2/{sample}.log'
        benchmark:
            benchmark_dir + 'subsample_read2/{sample}.txt'
        shell:
            """
            export PATH=$CONDA_PREFIX/bin:$PATH
            seqkit sample --two-pass -j {threads} -n {params.n} \
              {input.reads} > {output.reads} 2> {log}
            """
else:
    localrules: symlink_reads
    rule symlink_reads:
        """
        Uncompressing reads
        """
        input:
            read1 = lambda wildcards: config['genomes_tbl'].loc[config['genomes_tbl'].Sample == wildcards.sample, 'Read1'].unique().tolist(),
            read2 = lambda wildcards: config['genomes_tbl'].loc[config['genomes_tbl'].Sample == wildcards.sample, 'Read2'].unique().tolist()
        output:
            read1 = temp(config['tmp_dir'] + 'gs_map/reads/subsample/{sample}/R1.fq'),
            read2 = temp(config['tmp_dir'] + 'gs_map/reads/subsample/{sample}/R2.fq')
        log:
            log_dir + 'symlink_reads/{sample}.log'
        benchmark:
            benchmark_dir + 'symlink_reads/{sample}.txt'
        shell:
            """
            seqkit seq {input.read1} > {output.read1} 2> {log}
            seqkit seq {input.read2} > {output.read2} 2>> {log}
            """

rule map_read_filter:
    """
    Filtering reads via Skewer
    """
    input:
        read1 = config['tmp_dir'] + 'gs_map/reads/subsample/{sample}/R1.fq',
        read2 = config['tmp_dir'] + 'gs_map/reads/subsample/{sample}/R2.fq'
    output:
        read1 = temp(config['tmp_dir'] + 'gs_map/reads/filter/{sample}/R1.fq'),
        read2 = temp(config['tmp_dir'] + 'gs_map/reads/filter/{sample}/R2.fq')
    params:
        skewer = config['nonsim_params']['skewer'],
        read1 = config['tmp_dir'] + 'gs_map/reads/filter/{sample}/trimmed-pair1.fastq',
        read2 = config['tmp_dir'] + 'gs_map/reads/filter/{sample}/trimmed-pair2.fastq'
    conda:
        '../envs/bowtie2.yaml'
    threads:
        8
    resources:
        time = lambda wildcards, attempt: attempt ** 3 * 59,
        n = lambda wildcards, threads: threads,
        mem_gb_pt = lambda wildcards, attempt: attempt ** 2 + 1
    log:
        log_dir + 'map_read_filter/{sample}.log',    
    benchmark:
        benchmark_dir + 'map_read_filter/{sample}.txt'
    shell:
        """
        OUTDIR=`dirname {output.read1}`
        mkdir -p $OUTDIR
        skewer --threads {threads} {params.skewer} \
          -o $OUTDIR"/" {input.read1} {input.read2} 2> {log} 1>&2
        mv {params.read1} {output.read1} 2> {log} 1>&2
        mv {params.read2} {output.read2} 2>> {log} 1>&2
        """
            
rule map_bowtie2_build:
    """
    Building bowtie2 index for each genome
    """
    input:
        fna = config['tmp_dir'] + 'gs_map/genomes/{genome}.fna'
    output:
        touch(config['tmp_dir'] + 'gs_map/genomes/{genome}.bt2.index.done')
    threads:
        8
    resources:
        time = lambda wildcards, attempt: attempt * 59,
        n = lambda wildcards, threads: threads,
	mem_gb_pt = lambda wildcards, attempt: attempt ** 2 + 2
    conda:
        '../envs/bowtie2.yaml'
    log:
        log_dir + 'map_bowtie2_build/{genome}.log'
    benchmark:
        benchmark_dir + 'map_bowtie2_build/{genome}.log'
    shell:
        """
        export PATH=$CONDA_PREFIX/bin:$PATH
	PREF=`echo {input.fna} | perl -pe 's/\.[^.]+$//'`
        bowtie2-build --threads {threads} \
          {input.fna} $PREF 2> {log} 1>&2
        """
        
rule map_bowtie2:
    """
    Mapping reads from origin sample to the ref genome(s)
    """
    input:
        ref = config['tmp_dir'] + 'gs_map/genomes/{genome}.fna',
        done = config['tmp_dir'] + 'gs_map/genomes/{genome}.bt2.index.done',
        read1 = config['tmp_dir'] + 'gs_map/reads/filter/{sample}/R1.fq',
        read2 = config['tmp_dir'] + 'gs_map/reads/filter/{sample}/R2.fq'
    output:
        bam = config['tmp_dir'] + 'gs_map/map/{genome}/{sample}.bam'
    params:
        samtools = config['params']['samtools']
    conda:
        '../envs/bowtie2.yaml'
    threads:
        8
    resources:
        time = lambda wildcards, attempt: attempt * 60 * 12,
        n = lambda wildcards, threads: threads,
        mem_gb_pt = lambda wildcards, attempt: attempt ** 2 + 3
    log:
        bt2 = log_dir + 'map_bowtie2/{genome}/{sample}.log',    
        sam = log_dir + 'map_bowtie2_samtools/{genome}/{sample}.log'
    benchmark:
        benchmark_dir + 'map_bowtie2/{genome}/{sample}.txt'
    shell:
        """
        export PATH=$CONDA_PREFIX/bin:$PATH
        rm -f {log.sam}
	PREF=`echo {input.ref} | perl -pe 's/\.[^.]+$//'`
        TMPDIR=`dirname {output.bam}`
 
        bowtie2 -p {threads} -q --no-unal \
          -x $PREF -1 {input.read1} -2 {input.read2} 2> {log.bt2} | \
          samtools view {params.samtools} -h -o - 2>> {log.sam}| \
          samtools sort -@ {threads} -T $TMPDIR -o - \
          > {output.bam} 2>> {log.sam}
        """

rule map_bowtie2_index_bam:
    """
    Indexing BAM
    """
    input:
        bam = config['tmp_dir'] + 'gs_map/map/{genome}/{sample}.bam'
    output:
        bai = config['tmp_dir'] + 'gs_map/map/{genome}/{sample}.bam.bai'
    threads:
        8
    resources:
        time = lambda wildcards, attempt: attempt ** 3 * 59,
        n = lambda wildcards, threads: threads,
        mem_gb_pt = lambda wildcards, attempt: attempt * 2
    conda:
        '../envs/bowtie2.yaml'
    log:
        log_dir + 'map_bowtie2_index_bam/{genome}/{sample}.log'
    benchmark:
        benchmark_dir + 'map_bowtie2_index_bam/{genome}/{sample}.txt'
    shell:
        """
        export PATH=$CONDA_PREFIX/bin:$PATH
        samtools index -@ {threads} {input.bam} 2> {log}
        """
        
rule map_samtools_faidx:
    """
    Running samtools faidx on ref genome (indexing)
    """
    input:
        config['tmp_dir'] + 'gs_map/genomes/{genome}.fna'
    output:
        temp(config['tmp_dir'] + 'gs_map/genomes/{genome}.fna.fai')
    resources:
        time = lambda wildcards, attempt: attempt ** 3 * 59,
        mem_gb_pt = lambda wildcards, attempt: attempt * 12
    conda:
        '../envs/bowtie2.yaml'
    log:
        log_dir + 'map_samtools_faidx/{genome}.log'
    benchmark:
        benchmark_dir + 'map_samtools_faidx/{genome}.txt'
    shell:
        """
        export PATH=$CONDA_PREFIX/bin:$PATH
        samtools faidx {input} 2> {log} 1>&2
        """
        
rule map_bam_subsample:
    """
    Subsampling BAM to max per-contig coverage
    """
    input:
        fna = config['tmp_dir'] + 'gs_map/genomes/{genome}.fna',
        fai = config['tmp_dir'] + 'gs_map/genomes/{genome}.fna.fai',
        bam = config['tmp_dir'] + 'gs_map/map/{genome}/{sample}.bam',
        bai = config['tmp_dir'] + 'gs_map/map/{genome}/{sample}.bam.bai'
    output:
        bam = temp(config['tmp_dir'] + 'gs_map/map-sub/{genome}/subsample/{sample}.bam')
    params:
        mc = config['nonsim_params']['max_coverage'],
        exe = config['pipeline']['script_folder'] + 'bam_subsample.py'
    resources:
        time = lambda wildcards, attempt: attempt ** 3 * 59,
        mem_gb_pt = lambda wildcards, attempt: attempt ** 2 * 12
    conda:
        '../envs/bowtie2.yaml'
    log:
        log_dir + 'map_bam_subsample/{genome}/{sample}.log'
    benchmark:
        benchmark_dir + 'map_bam_subsample/{genome}/{sample}.txt'
    shell:
        """
        export PATH=$CONDA_PREFIX/bin:$PATH
        {params.exe} -o {output.bam} -m {params.mc} {input.bam} {input.fna}
        """
        
rule map_bowtie2_index_subsampled_bam:
    """
    Indexing BAM
    """
    input:
        bam = config['tmp_dir'] + 'gs_map/map-sub/{genome}/subsample/{sample}.bam'
    output:
        bai = temp(config['tmp_dir'] + 'gs_map/map-sub/{genome}/subsample/{sample}.bam.bai')
    threads:
        4
    resources:
        time = lambda wildcards, attempt: attempt ** 3 * 59,
        n = lambda wildcards, threads: threads,
        mem_gb_pt = lambda wildcards, attempt: attempt * 4
    conda:
        '../envs/bowtie2.yaml'
    log:
        log_dir + 'map_bowtie2_index_subsampled_bam/{genome}/{sample}.log'
    benchmark:
        benchmark_dir + 'map_bowtie2_index_subsampled_bam/{genome}/{sample}.txt'
    shell:
        """
        export PATH=$CONDA_PREFIX/bin:$PATH
        samtools index -@ {threads} {input.bam} 2> {log}
        """

rule bam_to_DL_features:
    """
    Converting bam to features
    """
    input:
        fna = config['tmp_dir'] + 'gs_map/genomes/{genome}.fna',
        fai = config['tmp_dir'] + 'gs_map/genomes/{genome}.fna.fai',
        bam = config['tmp_dir'] + 'gs_map/map-sub/{genome}/subsample/{sample}.bam',
        bai = config['tmp_dir'] + 'gs_map/map-sub/{genome}/subsample/{sample}.bam.bai'
    output:
        tsv = temp(config['tmp_dir'] + 'gs_map/feats/{genome}/{sample}/features.tsv')
    params:
        exe = config['pipeline']['script_folder'] + 'bam2feat',
	params = config['nonsim_params']['make_features']
    threads:
        4
    resources:
        time = lambda wildcards, attempt: attempt ** 2 * 60 * 12,
        n = lambda wildcards, threads: threads,
        mem_gb_pt = lambda wildcards, attempt: attempt ** 3 * 6
    conda:
        '../envs/bowtie2.yaml'
    log:
        log_dir + 'bam_to_DL_features/{genome}/{sample}.log'
    benchmark:
        benchmark_dir + 'bam_to_DL_features/{genome}/{sample}.txt'
    shell:
        """
        export PATH=$CONDA_PREFIX/bin:$PATH
        {params.exe} {params.params} --procs {threads} \
          --batches 100 --chunks 100 --assembler None \
          --bam_file {input.bam} \
          --fasta_file {input.fna} \
          --o {output.tsv} \
          2> {log} 1>&2
        """

rule features_compress:
    """
    Compressing table
    """
    input:
        config['tmp_dir'] + 'gs_map/feats/{genome}/{sample}/features.tsv'
    output:
        map_dir + '{genome}/{sample}/features.tsv.gz'
    params:
        ionice = config['params']['ionice']
    resources:
        time = lambda wildcards, attempt: attempt ** 3 * 59,        
        mem_gb_pt = lambda wildcards, attempt: attempt ** 2 * 8
    log:
        log_dir + 'features_compress/{genome}/{sample}.log'
    benchmark:
        benchmark_dir + 'features_compress/{genome}/{sample}.txt'
    shell:
        """
        ionice {params.ionice} gzip -c {input} > {output} 2> {log}
        """

def all_feat_tables(wildcards):
    genomes_tbl = config['genomes_tbl']
    out_files = []
    for i,x in genomes_tbl.iterrows():
        f = '{genome}/{sample}/features.tsv.gz'
	f = f.format(genome=x['Taxon'], sample=x['Sample'])
	f = map_dir + f
	out_files.append(f)
    return out_files
        
localrules: features_file_table        
rule features_file_table:
    """
    Creating a table that lists all feature files
    """
    input:
        feats = all_feat_tables
    output:
        tsv = map_dir + 'feature_files.tsv'
    log:
        log_dir + 'features_file_table.log'
    run:
        import os,sys
        cols = ['genome', 'sample', 'feature_file']
        with open(output.tsv, 'w') as outF:
            outF.write('\t'.join(cols) + '\n')
            for F in input.feats:
                D,feat_file = os.path.split(F)
                D,sample = os.path.split(D)
                D,genome = os.path.split(D)
                x = '\t'.join([genome, sample, F])
                outF.write(x + '\n')

rule bam_copy:
    """
    Copying BAM to final output
    """
    input:
        config['tmp_dir'] + 'gs_map/map-sub/{genome}/subsample/{sample}.bam',
    output:
        map_dir + '{genome}/{sample}.bam'
    params:
        ionice = config['params']['ionice']
    resources:
        time = lambda wildcards, attempt: attempt ** 3 * 59,
        mem_gb_pt = lambda wildcards, attempt: attempt ** 3 * 6
    log:
        log_dir + 'bam_copy/{genome}/{sample}.log'
    shell:
        """
        ionice {params.ionice} cp -f {input} {output} 2> {log} 1>&2
        """
